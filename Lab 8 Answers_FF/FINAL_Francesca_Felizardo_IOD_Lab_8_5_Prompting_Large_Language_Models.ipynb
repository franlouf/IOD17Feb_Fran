{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "469eccff-f2d9-47e6-b2e7-86b8401d8d9b",
      "metadata": {
        "id": "469eccff-f2d9-47e6-b2e7-86b8401d8d9b"
      },
      "source": [
        "<div>\n",
        "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a81de7-1bfa-4e29-98d8-e98162bb7612",
      "metadata": {
        "id": "57a81de7-1bfa-4e29-98d8-e98162bb7612"
      },
      "source": [
        "# Lab 8.5 - Prompting Large Language Models\n",
        "\n",
        "In this lab we will practise prompting with a few Large Language Models (LLMs) using Groq (not to be confused with Grok). Groq is a platform that provides access to their custom-built AI hardware via APIs, allowing users to run open-source models such as Llama.\n",
        "\n",
        "We shall see that while LLMs are powerful tools, how you ask a question or frame a task can dramatically influence the results obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca332d1-638f-44c8-9f20-eab2f62bec2a",
      "metadata": {
        "id": "7ca332d1-638f-44c8-9f20-eab2f62bec2a"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111d6485-4dd7-47d7-a0f4-eba2a6cb3719",
      "metadata": {
        "id": "111d6485-4dd7-47d7-a0f4-eba2a6cb3719"
      },
      "source": [
        "Step 1: Sign up for a free Groq account at https://console.groq.com/home .\n",
        "\n",
        "Step 2: Create a new API key at https://console.groq.com/keys. Copy-paste it into an empty text file called 'groq_key.txt'.\n",
        "\n",
        "Running the next cell will then read in this key and assign it to the variable `groq_key`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will prompt you to upload a file\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "K7DWqaCOZW7O",
        "outputId": "73e6f732-1b94-4070-e0b4-3d55dd28bef5"
      },
      "id": "K7DWqaCOZW7O",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-87fdb938-8cc8-49c0-a474-214a6fcfba42\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-87fdb938-8cc8-49c0-a474-214a6fcfba42\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving groq_key.txt to groq_key.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5ba1c784-46dc-4aad-a2cd-02a2db70ffe0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ba1c784-46dc-4aad-a2cd-02a2db70ffe0",
        "outputId": "8ff5bd71-66d6-4422-9e81-e0c001bbf719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "56441b82-ddc5-46e9-9583-878e8a807b7f",
      "metadata": {
        "id": "56441b82-ddc5-46e9-9583-878e8a807b7f"
      },
      "outputs": [],
      "source": [
        "groqfilename = 'groq_key.txt' # this file contains a single line containing your Groq API key only\n",
        "try:\n",
        "    with open(groqfilename, 'r') as f:\n",
        "        groq_key = f.read().strip()\n",
        "except FileNotFoundError:\n",
        "    print(\"'%s' file not found\" % groqfilename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "606b6102-4a13-44bb-9324-d1f9aff8ac88",
      "metadata": {
        "id": "606b6102-4a13-44bb-9324-d1f9aff8ac88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4579afd-1ec3-426f-8542-0a0a938de833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.30.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.30.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m687.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.30.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dd0b4dfc-47a9-46f9-ae1a-6241b07ba41c",
      "metadata": {
        "id": "dd0b4dfc-47a9-46f9-ae1a-6241b07ba41c"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "import requests\n",
        "import pandas as pd\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eef37e2-24ba-4e6d-a8ce-87ade1ef1227",
      "metadata": {
        "id": "1eef37e2-24ba-4e6d-a8ce-87ade1ef1227"
      },
      "source": [
        "First create an instance of the Groq client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "54fec468-0ae0-42e1-ab8c-087b97c9818b",
      "metadata": {
        "id": "54fec468-0ae0-42e1-ab8c-087b97c9818b"
      },
      "outputs": [],
      "source": [
        "client = Groq(api_key=groq_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a097cd77-7a8d-4502-ae6e-607782706b26",
      "metadata": {
        "id": "a097cd77-7a8d-4502-ae6e-607782706b26"
      },
      "source": [
        "The following code shows what models are currently accessible through Groq. `context_window` refers to the size of memory (in tokens) during a session and `max_completion_tokens` is the maximum number of tokens that are generated in an output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "33fc8058-c9c7-49b3-b294-cb4e12de20f4",
      "metadata": {
        "id": "33fc8058-c9c7-49b3-b294-cb4e12de20f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "a096ffad-e21d-4c8b-df51-07d93a8442cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               id object     created  \\\n",
              "12                    moonshotai/kimi-k2-instruct  model  1752435491   \n",
              "7             meta-llama/llama-prompt-guard-2-86m  model  1748632165   \n",
              "15            meta-llama/llama-prompt-guard-2-22m  model  1748632101   \n",
              "3                                  qwen/qwen3-32b  model  1748396646   \n",
              "17                   meta-llama/llama-guard-4-12b  model  1746743847   \n",
              "0   meta-llama/llama-4-maverick-17b-128e-instruct  model  1743877158   \n",
              "6       meta-llama/llama-4-scout-17b-16e-instruct  model  1743874824   \n",
              "10                             compound-beta-mini  model  1742953279   \n",
              "9                                   compound-beta  model  1740880017   \n",
              "20                              playai-tts-arabic  model  1740682783   \n",
              "18                                     playai-tts  model  1740682771   \n",
              "8                                mistral-saba-24b  model  1739996492   \n",
              "13                  deepseek-r1-distill-llama-70b  model  1737924940   \n",
              "5                                      allam-2-7b  model  1737672203   \n",
              "14                        llama-3.3-70b-versatile  model  1733447754   \n",
              "19                         whisper-large-v3-turbo  model  1728413088   \n",
              "1                            llama-3.1-8b-instant  model  1693721698   \n",
              "2                                    gemma2-9b-it  model  1693721698   \n",
              "4                      distil-whisper-large-v3-en  model  1693721698   \n",
              "11                                 llama3-8b-8192  model  1693721698   \n",
              "16                               whisper-large-v3  model  1693721698   \n",
              "21                                llama3-70b-8192  model  1693721698   \n",
              "\n",
              "           owned_by  active  context_window public_apps  max_completion_tokens  \n",
              "12      Moonshot AI    True          131072        None                  16384  \n",
              "7              Meta    True             512        None                    512  \n",
              "15             Meta    True             512        None                    512  \n",
              "3     Alibaba Cloud    True          131072        None                  40960  \n",
              "17             Meta    True          131072        None                   1024  \n",
              "0              Meta    True          131072        None                   8192  \n",
              "6              Meta    True          131072        None                   8192  \n",
              "10             Groq    True          131072        None                   8192  \n",
              "9              Groq    True          131072        None                   8192  \n",
              "20           PlayAI    True            8192        None                   8192  \n",
              "18           PlayAI    True            8192        None                   8192  \n",
              "8        Mistral AI    True           32768        None                  32768  \n",
              "13  DeepSeek / Meta    True          131072        None                 131072  \n",
              "5             SDAIA    True            4096        None                   4096  \n",
              "14             Meta    True          131072        None                  32768  \n",
              "19           OpenAI    True             448        None                    448  \n",
              "1              Meta    True          131072        None                 131072  \n",
              "2            Google    True            8192        None                   8192  \n",
              "4      Hugging Face    True             448        None                    448  \n",
              "11             Meta    True            8192        None                   8192  \n",
              "16           OpenAI    True             448        None                    448  \n",
              "21             Meta    True            8192        None                   8192  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d7d782a-b6b5-4d92-a9ad-b9a3a6459e86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>object</th>\n",
              "      <th>created</th>\n",
              "      <th>owned_by</th>\n",
              "      <th>active</th>\n",
              "      <th>context_window</th>\n",
              "      <th>public_apps</th>\n",
              "      <th>max_completion_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>moonshotai/kimi-k2-instruct</td>\n",
              "      <td>model</td>\n",
              "      <td>1752435491</td>\n",
              "      <td>Moonshot AI</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>16384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>meta-llama/llama-prompt-guard-2-86m</td>\n",
              "      <td>model</td>\n",
              "      <td>1748632165</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>512</td>\n",
              "      <td>None</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>meta-llama/llama-prompt-guard-2-22m</td>\n",
              "      <td>model</td>\n",
              "      <td>1748632101</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>512</td>\n",
              "      <td>None</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>qwen/qwen3-32b</td>\n",
              "      <td>model</td>\n",
              "      <td>1748396646</td>\n",
              "      <td>Alibaba Cloud</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>40960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>meta-llama/llama-guard-4-12b</td>\n",
              "      <td>model</td>\n",
              "      <td>1746743847</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meta-llama/llama-4-maverick-17b-128e-instruct</td>\n",
              "      <td>model</td>\n",
              "      <td>1743877158</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>meta-llama/llama-4-scout-17b-16e-instruct</td>\n",
              "      <td>model</td>\n",
              "      <td>1743874824</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>compound-beta-mini</td>\n",
              "      <td>model</td>\n",
              "      <td>1742953279</td>\n",
              "      <td>Groq</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>compound-beta</td>\n",
              "      <td>model</td>\n",
              "      <td>1740880017</td>\n",
              "      <td>Groq</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>playai-tts-arabic</td>\n",
              "      <td>model</td>\n",
              "      <td>1740682783</td>\n",
              "      <td>PlayAI</td>\n",
              "      <td>True</td>\n",
              "      <td>8192</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>playai-tts</td>\n",
              "      <td>model</td>\n",
              "      <td>1740682771</td>\n",
              "      <td>PlayAI</td>\n",
              "      <td>True</td>\n",
              "      <td>8192</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mistral-saba-24b</td>\n",
              "      <td>model</td>\n",
              "      <td>1739996492</td>\n",
              "      <td>Mistral AI</td>\n",
              "      <td>True</td>\n",
              "      <td>32768</td>\n",
              "      <td>None</td>\n",
              "      <td>32768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>deepseek-r1-distill-llama-70b</td>\n",
              "      <td>model</td>\n",
              "      <td>1737924940</td>\n",
              "      <td>DeepSeek / Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>131072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>allam-2-7b</td>\n",
              "      <td>model</td>\n",
              "      <td>1737672203</td>\n",
              "      <td>SDAIA</td>\n",
              "      <td>True</td>\n",
              "      <td>4096</td>\n",
              "      <td>None</td>\n",
              "      <td>4096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>llama-3.3-70b-versatile</td>\n",
              "      <td>model</td>\n",
              "      <td>1733447754</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>32768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>whisper-large-v3-turbo</td>\n",
              "      <td>model</td>\n",
              "      <td>1728413088</td>\n",
              "      <td>OpenAI</td>\n",
              "      <td>True</td>\n",
              "      <td>448</td>\n",
              "      <td>None</td>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>llama-3.1-8b-instant</td>\n",
              "      <td>model</td>\n",
              "      <td>1693721698</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>131072</td>\n",
              "      <td>None</td>\n",
              "      <td>131072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gemma2-9b-it</td>\n",
              "      <td>model</td>\n",
              "      <td>1693721698</td>\n",
              "      <td>Google</td>\n",
              "      <td>True</td>\n",
              "      <td>8192</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>distil-whisper-large-v3-en</td>\n",
              "      <td>model</td>\n",
              "      <td>1693721698</td>\n",
              "      <td>Hugging Face</td>\n",
              "      <td>True</td>\n",
              "      <td>448</td>\n",
              "      <td>None</td>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>llama3-8b-8192</td>\n",
              "      <td>model</td>\n",
              "      <td>1693721698</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>8192</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>whisper-large-v3</td>\n",
              "      <td>model</td>\n",
              "      <td>1693721698</td>\n",
              "      <td>OpenAI</td>\n",
              "      <td>True</td>\n",
              "      <td>448</td>\n",
              "      <td>None</td>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>llama3-70b-8192</td>\n",
              "      <td>model</td>\n",
              "      <td>1693721698</td>\n",
              "      <td>Meta</td>\n",
              "      <td>True</td>\n",
              "      <td>8192</td>\n",
              "      <td>None</td>\n",
              "      <td>8192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d7d782a-b6b5-4d92-a9ad-b9a3a6459e86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d7d782a-b6b5-4d92-a9ad-b9a3a6459e86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d7d782a-b6b5-4d92-a9ad-b9a3a6459e86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7efb95df-078a-4c53-8995-2fc744d4eb29\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7efb95df-078a-4c53-8995-2fc744d4eb29')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7efb95df-078a-4c53-8995-2fc744d4eb29 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "url = \"https://api.groq.com/openai/v1/models\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {groq_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "pd.DataFrame(response.json()['data']).sort_values(['created'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b438489-c102-434b-872d-e807169deef6",
      "metadata": {
        "id": "2b438489-c102-434b-872d-e807169deef6"
      },
      "source": [
        "The Groq client object enables interaction with the Groq REST API and a chat completion request is made via the client.chat.completions.create method.\n",
        "\n",
        "The most important arguments of the client.chat.completions.create method are the following:\n",
        "* messages: a list of messages (dictionary form) that make up the conversation to date\n",
        "* model: a string indicating which model to use (see [list of models](https://console.groq.com/docs/models))\n",
        "* max_completion_tokens: the maximum number of tokens that are generated in the chat completion\n",
        "* response_format: setting this to `{ \"type\": \"json_object\" }` enables JSON output\n",
        "* seed: sample deterministically as best as possible, though identical outputs each time are not guaranteed\n",
        "* temperature: between 0 and 2 where higher values like 0.8 make the output more random (creative) and values like 0.2 are more focused and deterministic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "99216392-acc3-4a00-826b-c166a1e52534",
      "metadata": {
        "id": "99216392-acc3-4a00-826b-c166a1e52534"
      },
      "outputs": [],
      "source": [
        "# help(client.chat.completions.create)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d17d3c7-d7b5-47ed-b514-40b0a3e577b7",
      "metadata": {
        "id": "4d17d3c7-d7b5-47ed-b514-40b0a3e577b7"
      },
      "source": [
        "As a first example, note how the messages input is given as a list of a dictionaries with `role` and `content` keys. This is in a ChatML format recognised by many LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9cfd33fb-15fc-409d-a5a9-e8770885df81",
      "metadata": {
        "id": "9cfd33fb-15fc-409d-a5a9-e8770885df81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c147285-d409-46d4-f99c-30ce09f6cf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large language models are artificial intelligence (AI) systems that process and generate human-like language. They work by:\n",
            "\n",
            "1. **Training on vast amounts of text data**: Models are trained on massive datasets of written language, such as books, articles, and conversations.\n",
            "2. **Learning patterns and relationships**: Through complex algorithms, the models identify patterns, relationships, and context within the training data.\n",
            "3. **Generating text based on probability**: When given a prompt or input, the model predicts the next word or character based on the patterns and relationships it learned during training.\n",
            "4. **Iterating and refining**: The model continues to generate text, refining its output based on the input and its internal understanding of language.\n",
            "\n",
            "This process allows large language models to generate coherent and often contextual text, simulating human-like conversation and writing.\n"
          ]
        }
      ],
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {   \"role\": \"system\", # sets the persona of the model\n",
        "            \"content\": \"You are a helpful assistant.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\", # what the user wants the assistant to do\n",
        "            \"content\": \"Explain briefly how large language models work\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "728b60c2-4300-4338-b325-c3ea876c1afe",
      "metadata": {
        "id": "728b60c2-4300-4338-b325-c3ea876c1afe"
      },
      "source": [
        "The output is in Markdown format so the following line formats this text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "88845bb3-4a3e-403a-93ab-439c46aa1832",
      "metadata": {
        "id": "88845bb3-4a3e-403a-93ab-439c46aa1832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "7adbdbc0-95aa-4358-a266-a657aab4fcc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Large language models are artificial intelligence (AI) systems that process and generate human-like language. They work by:\n\n1. **Training on vast amounts of text data**: Models are trained on massive datasets of written language, such as books, articles, and conversations.\n2. **Learning patterns and relationships**: Through complex algorithms, the models identify patterns, relationships, and context within the training data.\n3. **Generating text based on probability**: When given a prompt or input, the model predicts the next word or character based on the patterns and relationships it learned during training.\n4. **Iterating and refining**: The model continues to generate text, refining its output based on the input and its internal understanding of language.\n\nThis process allows large language models to generate coherent and often contextual text, simulating human-like conversation and writing."
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "Markdown(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c8c97b-1711-4355-b108-86bed769c109",
      "metadata": {
        "id": "e1c8c97b-1711-4355-b108-86bed769c109"
      },
      "source": [
        "## Text summarisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "930cdd6b-8d44-4b3e-b161-0ebcd4600bc4",
      "metadata": {
        "id": "930cdd6b-8d44-4b3e-b161-0ebcd4600bc4"
      },
      "source": [
        "We start with a llama3-8b-8192, a model using just over 8 billion parameters with at most 8192 tokens produced as output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b56002-d85b-44d6-a2d0-4b1513eeb4f2",
      "metadata": {
        "id": "b7b56002-d85b-44d6-a2d0-4b1513eeb4f2"
      },
      "source": [
        "Here is an article to be summarised from the [cnn_dailymail](https://huggingface.co/datasets/cnn_dailymail) dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7c426f9f-c780-4ca6-b913-9b5c63b8bb29",
      "metadata": {
        "id": "7c426f9f-c780-4ca6-b913-9b5c63b8bb29"
      },
      "outputs": [],
      "source": [
        "story = \"\"\"\n",
        "SAN FRANCISCO, California (CNN) -- A magnitude 4.2 earthquake shook the San Francisco area Friday at 4:42 a.m. PT (7:42 a.m. ET), the U.S. Geological Survey reported. The quake left about 2,000 customers without power, said David Eisenhower, a spokesman for Pacific Gas and Light. Under the USGS classification, a magnitude 4.2 earthquake is considered \"light,\" which it says usually causes minimal damage. \"We had quite a spike in calls, mostly calls of inquiry, none of any injury, none of any damage that was reported,\" said Capt. Al Casciato of the San Francisco police. \"It was fairly mild.\" Watch police describe concerned calls immediately after the quake » . The quake was centered about two miles east-northeast of Oakland, at a depth of 3.6 miles, the USGS said. Oakland is just east of San Francisco, across San Francisco Bay. An Oakland police dispatcher told CNN the quake set off alarms at people's homes. The shaking lasted about 50 seconds, said CNN meteorologist Chad Myers. According to the USGS, magnitude 4.2 quakes are felt indoors and may break dishes and windows and overturn unstable objects. Pendulum clocks may stop.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9754257a-74ff-4747-a18e-7ebfbc82639c",
      "metadata": {
        "id": "9754257a-74ff-4747-a18e-7ebfbc82639c"
      },
      "source": [
        "**Exercise:**\n",
        "Summarise the story text using the following three prompts. Use the format given above but here there is no need to set the persona (i.e. only include one dictionary in the messages list when calling `client.chat.completions.create`.) Comment on any differences.\n",
        "\n",
        "1) \"Summarise the following article in 3 sentences.\"\n",
        "\n",
        "2) \"Give me a TL;DR of this text.\"\n",
        "\n",
        "3) \"What's the key takeaway here?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9c372155-bdde-45a4-a184-fce4c4e8034c",
      "metadata": {
        "id": "9c372155-bdde-45a4-a184-fce4c4e8034c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd970345-d65e-49cf-eee7-fa6bbc13a22c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarise the following article in 3 sentences.  \n",
            " Here is a summary of the article in 3 sentences:\n",
            "\n",
            "A magnitude 4.2 earthquake struck the San Francisco area on Friday morning, with its epicenter located 2 miles east-northeast of Oakland at a depth of 3.6 miles. The quake caused minimal damage and disruption, with about 2,000 customers losing power and no reports of injury or damage. The shaking lasted around 50 seconds and was felt indoors, with some people experiencing alarm going off at their homes and pendulum clocks stopping due to the quake.\n",
            "Give me a TL;DR of this text.  \n",
            " Here is a brief summary of the text:\n",
            "\n",
            "A magnitude 4.2 earthquake occurred in the San Francisco area on Friday morning, causing minimal damage and no reported injuries. The quake left around 2,000 customers without power, but authorities say it was \"fairly mild\" and mostly caused concern among residents, rather than damage.\n",
            "What's the key takeaway here? \n",
            " The key takeaway is that a magnitude 4.2 earthquake struck the San Francisco area on Friday morning, causing minimal damage and no reported injuries. The quake was felt for about 50 seconds and left around 2,000 customers without power, but overall was considered \"light\" and did not cause significant damage.\n"
          ]
        }
      ],
      "source": [
        "prompts = [\"Summarise the following article in 3 sentences. \", \"Give me a TL;DR of this text. \", \"What's the key takeaway here?\"]\n",
        "#content will be p + story for p in prompts\n",
        "\n",
        "# ANSWER\n",
        "for p in prompts:\n",
        "    response = client.chat.completions.create(\n",
        "                model=\"llama3-8b-8192\",\n",
        "                messages=[{\"role\": \"user\", \"content\": p + story}]\n",
        ")\n",
        "\n",
        "    print(p, '\\n', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3634dd68-a9c1-42a2-a1ef-eb1487cbf9df",
      "metadata": {
        "id": "3634dd68-a9c1-42a2-a1ef-eb1487cbf9df"
      },
      "source": [
        "Run the above code again below and note that the answers may differ. This is due to the probabilistic nature of LLM token generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f7dffda3-fb3b-4555-b6c6-9bbc33248c14",
      "metadata": {
        "id": "f7dffda3-fb3b-4555-b6c6-9bbc33248c14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4ba462-371c-4b95-f7de-0aceb97d0fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarise the following article in 3 sentences.  \n",
            " Here is a summary of the article in 3 sentences:\n",
            "\n",
            "A magnitude 4.2 earthquake struck the San Francisco area on Friday morning, causing minimal damage and leaving around 2,000 customers without power. The quake was considered \"light\" by the USGS, with no reports of injuries or significant damage, according to police. The shaking lasted around 50 seconds and was felt indoors, causing some objects to fall and overturn, but some people's homes were also set off by alarms.\n",
            "Give me a TL;DR of this text.  \n",
            " A 4.2 magnitude earthquake struck the San Francisco area at 4:42am, causing about 2,000 customers to lose power. Although considered a \"light\" earthquake, it caused some alarm and set off home alarms in Oakland. The shaking lasted about 50 seconds and was felt indoors, but no injuries or damage have been reported.\n",
            "What's the key takeaway here? \n",
            " The key takeaway is that a magnitude 4.2 earthquake struck the San Francisco area, causing minimal damage and no reported injuries. The quake was described as \"fairly mild\" and the majority of calls to emergency services were from concerned citizens, with no reports of damage or injury.\n"
          ]
        }
      ],
      "source": [
        "# ANSWER\n",
        "for p in prompts:\n",
        "    response = client.chat.completions.create(\n",
        "                model=\"llama3-8b-8192\",\n",
        "                messages=[{\"role\": \"user\", \"content\": p + story}]\n",
        ")\n",
        "\n",
        "    print(p, '\\n', response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97b4a80d-acb8-4099-b8e2-dba4a372369f",
      "metadata": {
        "id": "97b4a80d-acb8-4099-b8e2-dba4a372369f"
      },
      "source": [
        "## Text completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b0be4be-e054-4b9c-ad38-843c97d3afaf",
      "metadata": {
        "id": "2b0be4be-e054-4b9c-ad38-843c97d3afaf"
      },
      "source": [
        "**Exercise**: In this section adjust the `max_completion_tokens` and `temperature` settings below to obtain different responses. Show some examples with the prompt \"Continue the story: It was a great time to be alive\" with the model \"llama-3.1-8b-instant\".\n",
        "\n",
        "* max_completion_tokens - the maximum number of tokens to generate. Note that longer words are made of multiple tokens (set to 200 and 500)\n",
        "* temperature (positive number) - the higher the number the more random (creative) the output (set to 0.2, 0.8, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "50207704-94be-4309-8a82-dc1d22a063ee",
      "metadata": {
        "id": "50207704-94be-4309-8a82-dc1d22a063ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba6a5c8-b642-431b-e8ae-8f2959fc386d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a great time to be alive, thought Emily as she walked through the bustling streets of New York City. The year was 2025, and technology had surpassed anything she could have imagined. Self-driving cars zoomed by, their sleek designs and bright colors a stark contrast to the crowded sidewalks.\n",
            "\n",
            "As she walked, Emily's augmented reality glasses beeped, alerting her to a pop-up notification from her friend, Sarah. \"Hey, Emily, meet me at Central Park at 3 PM,\" the message read. \"We're going to try out the new virtual reality hiking experience. Can't wait to climb Mount Everest from the comfort of our feet!\"\n",
            "\n",
            "Emily groaned, laughing to herself as she tapped her glasses to acknowledge the message. She had always been an adventurous spirit, and the idea of exploring the world from the comfort of her own neighborhood was both exhilarating and terrifying.\n",
            "\n",
            "As she continued her walk, Emily passed by a group of people gathered around a holographic display projecting\n"
          ]
        }
      ],
      "source": [
        "# ANSWER (set max_completion_tokens=200, do not have a temperature setting)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Continue the story: It was a great time to be alive\"}],\n",
        "    max_completion_tokens=200,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "63235fcc-3a61-4829-998b-37f2f104322b",
      "metadata": {
        "id": "63235fcc-3a61-4829-998b-37f2f104322b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b0b659-4b93-47d0-c420-9a39885a232a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sun was shining brightly, casting a warm glow over the bustling streets of the city. The air was alive with the chatter of people from all walks of life, their laughter and conversations weaving a rich tapestry of sound. It was a great time to be alive, indeed.\n",
            "\n",
            "As I walked down the sidewalk, I couldn't help but feel a sense of excitement and anticipation. The world seemed full of possibility, and I felt like anything was within my grasp. I had just graduated from college, and the possibilities stretched out before me like a map of uncharted territories.\n",
            "\n",
            "I stopped at a small café to grab a coffee and take in the view. The café was one of those eclectic, bohemian spots that seemed to attract a mix of creatives, entrepreneurs, and free-spirited individuals. The walls were adorned with vibrant artwork and the air was thick with the scent of freshly brewed coffee.\n",
            "\n",
            "As I sipped my latte, I struck up a conversation with a young woman sitting at a nearby table. She was a freelance writer, working on her first novel, and we quickly discovered a shared passion for literature and art. Our conversation flowed easily, like a gentle stream meandering through a lush meadow.\n",
            "\n",
            "As the morning wore on, I found myself feeling more and more at home in this vibrant, cosmopolitan city. Everywhere I looked, there were signs of growth, innovation, and progress. New restaurants, boutiques, and art galleries were sprouting up left and right, each one a testament to the city's boundless energy and creativity.\n",
            "\n",
            "But as the sun began to climb higher in the sky, casting a warm glow over the city, I couldn't shake the feeling that there was something more to this great time to be alive. Something that went beyond the surface-level excitement and possibility. As I gazed out the window, I felt a sense of restlessness, a nagging sense that I was missing something essential.\n",
            "\n",
            "And then, it hit me. What made this time so great wasn't just the external circumstances, but the sense of hope and optimism that permeated the air. A sense that any challenge could be overcome, that any dream could be achieved. A sense, above all, that the world was a place of endless possibility, where anything could be created and anything could be achieved.\n",
            "\n",
            "It was a feeling that I knew I couldn't keep to myself. I had to share it with others. But as I got up to leave the café,\n"
          ]
        }
      ],
      "source": [
        "# ANSWER (set max_completion_tokens=500, do not have a temperature setting)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Continue the story: It was a great time to be alive\"}],\n",
        "    max_completion_tokens=500,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8ac91a1a-4f55-4531-bb5b-cdb436a87e50",
      "metadata": {
        "id": "8ac91a1a-4f55-4531-bb5b-cdb436a87e50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a357d9-f478-4f08-e409-14a5fab8c8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sun was shining bright, casting a warm glow over the bustling streets of the city. People of all ages and backgrounds walked side by side, each with their own unique story to tell. The air was filled with the sweet scent of blooming flowers and the sound of laughter and music.\n",
            "\n",
            "As I walked through the crowded streets, I couldn't help but feel a sense of excitement and possibility. It was a great time to be alive, and I was grateful to be a part of it. The world was changing at an incredible pace, and it seemed like anything was possible.\n",
            "\n",
            "I passed by a group of street performers, who were drawing a large crowd with their acrobatic feats and mesmerizing magic tricks. I watched in awe as they spun plates and juggled balls, their movements fluid and precise.\n",
            "\n",
            "Next, I walked by a group of artists, who were showcasing their latest works on the sidewalk. Their vibrant paintings and sculptures seemed to come alive in the sunlight, and I couldn't help but be drawn in by their creativity and passion.\n",
            "\n",
            "As I continued on my way, I stumbled upon a small café, where a group of musicians were playing a lively set of music. The sounds of the guitar, violin, and drums filled the air, and I couldn't help but tap my foot along with the beat.\n",
            "\n",
            "I slipped inside the café, where I was greeted by the warm smile of the barista. She asked me what I wanted to drink, and I opted for a cold glass of lemonade. As I sipped my drink, I felt a sense of contentment wash over me. This was indeed a great time to be alive, and I was grateful to be a part of it.\n",
            "\n",
            "But as I sat there, lost in the moment, I couldn't shake the feeling that something was about to change. A sense of unease crept over me, and I looked around the café, wondering if anyone else felt it too. The musicians continued to play, the artists continued to create, and the street performers continued to entertain, but I couldn't shake the feeling that the world was on the cusp of something big.\n",
            "\n",
            "And then, just as I was starting to wonder what it could be, a sudden commotion erupted outside. People began to run and shout, and I looked out the window to see what was happening. A group of protesters had gathered in the street, holding signs and chanting slogans.\n",
            "\n",
            "I watched in confusion as the situation escalated, and the police arrived to try and disperse the crowd. It was clear that something was brewing, and I couldn't help but wonder what it was all about.\n",
            "\n",
            "As I sat there, trying to make sense of it all, I realized that this was indeed a great time to be alive. The world was changing at an incredible pace, and it seemed like anything was possible. But it was also a time of great uncertainty, and I couldn't help but wonder what the future held.\n",
            "\n",
            "I finished my drink, and stepped out into the chaos. The protesters were still shouting and chanting, and the police were trying to maintain order. I watched as the situation continued to unfold, and I couldn't help but feel a sense of excitement and trepidation.\n",
            "\n",
            "This was indeed a great time to be alive, but it was also a time of great change and uncertainty. And as I stood there, watching the chaos unfold, I couldn't help but wonder what the future held.\n"
          ]
        }
      ],
      "source": [
        "# ANSWER (set temperature = 0.2, do not have a max_completion_tokens setting)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Continue the story: It was a great time to be alive.\"}],\n",
        "    temperature = 0.2,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "27aef18a-eee4-4d30-9de9-f97a303ad78d",
      "metadata": {
        "id": "27aef18a-eee4-4d30-9de9-f97a303ad78d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9a61fa-db9d-47c4-b81b-f3252ac029c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a great time to be alive, the sun was shining bright, and the air was filled with the sweet scent of blooming flowers. The year was 1969, and the world was on the cusp of a new era of peace and prosperity. The Apollo 11 mission had just successfully landed on the moon, and the global community was united in their excitement and wonder.\n",
            "\n",
            "In a small town nestled in the heart of the countryside, a young couple, Emily and Jack, were experiencing the joy and promise of this new era. They had just graduated from college, and were embarking on a journey of self-discovery, love, and adventure.\n",
            "\n",
            "As they sat on a blanket in the park, watching the children play, Emily turned to Jack with a look of excitement in her eyes. \"Can you believe what's happening?\" she exclaimed. \"The world is changing so fast, and we're right in the middle of it.\"\n",
            "\n",
            "Jack smiled, and took her hand in his. \"I know, it's an amazing time to be alive. Anything seems possible.\"\n",
            "\n",
            "As they talked, they noticed a group of young musicians gathered near the pond, playing guitars and singing. The music was lively and energetic, and the crowd began to grow. Emily and Jack joined in, and soon they were dancing and singing along with the rest of the group.\n",
            "\n",
            "The music was a mix of folk, rock, and pop, with lyrics that spoke of social justice, love, and freedom. It was the kind of music that made you feel alive, and connected to the world around you.\n",
            "\n",
            "As the night wore on, and the music continued to play, Emily and Jack felt like they were part of something special. A movement, a revolution, a new way of living.\n",
            "\n",
            "And as they looked into each other's eyes, they knew that they were meant to be a part of it. To be the young couple who embodied the spirit of the times, who lived life to the fullest, and who made a difference in the world.\n",
            "\n",
            "Little did they know, their journey was just beginning, and it would take them to places they never thought possible. But for now, in this moment, surrounded by the beauty of nature, the magic of music, and the love of each other, they knew that it was a great time to be alive.\n"
          ]
        }
      ],
      "source": [
        "# ANSWER (set temperature = 1, do not have a max_completion_tokens setting)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Continue the story: It was a great time to be alive.\"}],\n",
        "    temperature = 1,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac38e059-e23a-44eb-92fc-3fec9c7bdcdf",
      "metadata": {
        "id": "ac38e059-e23a-44eb-92fc-3fec9c7bdcdf"
      },
      "source": [
        "Note what happens when the temperature is set too high!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "931f8e00-928c-4218-8e74-8c56269fbfcb",
      "metadata": {
        "id": "931f8e00-928c-4218-8e74-8c56269fbfcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c292b2b-a4bf-4e0d-d096-8e4ff5110f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "People of all ages gathered in cities and streets to rejoice in this moment of peace and prosperity. The war seemed like a distant memory, replaced by bustling markets, thriving arts scenes, and a collective sigh of relief.\n",
            "\n",
            "In one of those markets, Emily stood out among the crowds. Her bright smiles and infectious enthusiasm had made her a local celebrity of sorts, known for her vibrant paintings and infectious laughter. Among her colorful stalls, a large sign caught the eye - 'A Brighter Future for Sale, Price - $100 for a day, or forever, it's up to you'. Passersby laughed at the playful joke until some stopped, curiosity getting the better of them to look more intensely at the artwork displayed alongside it.\n",
            "\n",
            "Emily had lost her sister some few years ago, during a particularly dark period of war. But now she used those difficult memories as the foundation for something positive: she brought the artwork from an organization called 'Color for Life', where local street art artists and community artists were paid a living wage.\n"
          ]
        }
      ],
      "source": [
        "# ANSWER (set temperature = 2, do not have a max_completion_tokens setting)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Continue the story: It was a great time to be alive.\"}],\n",
        "    temperature = 2,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e9bd9a-ad6b-409b-a751-023575868b6c",
      "metadata": {
        "id": "f4e9bd9a-ad6b-409b-a751-023575868b6c"
      },
      "source": [
        "### Zero-shot and one-short prompting for question-answering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6662f0a-c7e3-4235-972d-2771781a4e53",
      "metadata": {
        "id": "f6662f0a-c7e3-4235-972d-2771781a4e53"
      },
      "source": [
        "This section shows the impact of prompting on the response. Zero-shot prompting means we provide the prompt without any examples or additional context. Let us initially ask Mistral a question using no prompting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e2d48674-a9cc-4e5a-8035-afcc37a01dfc",
      "metadata": {
        "id": "e2d48674-a9cc-4e5a-8035-afcc37a01dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "79a1833a-d54e-4bb4-a44f-7f609b520c0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "When two chemicals react, it's a complex process that involves the interaction of their atoms, molecules, and electrons. Here's a simplified overview:\n\n1. **Chemical Properties**: Each chemical has its own set of chemical properties, such as its reactivity, electronegativity, and molecular structure.\n2. **Reaction Conditions**: The reaction conditions, such as temperature, pressure, and concentration, can influence the reaction.\n3. **Mechanisms**: Chemical reactions can occur through different mechanisms, such as:\n\t* **Acid-base reactions**: The transfer of a proton (H+) or an electron pair.\n\t* **Redox reactions**: The transfer of electrons between two species.\n\t* **Substitution reactions**: The replacement of an atom or group of atoms.\n\t* **Condensation reactions**: The combination of two molecules to form a new molecule.\n\t* **Decomposition reactions**: The breaking down of a molecule into simpler molecules.\n4. **Collision Theory**: For a reaction to occur, the reactant molecules must collide with each other at a sufficient energy level, known as the activation energy.\n5. **Reaction Rate**: The rate of the reaction depends on the concentration of the reactants, the surface area of the reactants, and the temperature of the reaction.\n\nWhen two chemicals react, the following steps occur:\n\n1. **Collision**: The reactant molecules collide with each other.\n2. **Activation energy**: The colliding molecules must overcome the activation energy barrier to form an intermediate or a transition state.\n3. **Intermediate or transition state**: The intermediate or transition state is a temporary arrangement of atoms that is higher in energy than the reactants.\n4. **Product formation**: The intermediate or transition state breaks down to form the products.\n5. **Product distribution**: The products are distributed according to their equilibrium constants.\n\nHere's a simple example of a chemical reaction between two chemicals, hydrogen gas (H2) and oxygen gas (O2), to form water (H2O):\n\n2H2 (g) + O2 (g) → 2H2O (l)\n\nIn this reaction:\n\n1. The hydrogen and oxygen molecules collide with each other.\n2. The collided molecules overcome the activation energy barrier to form an intermediate or transition state.\n3. The intermediate or transition state breaks down to form water molecules.\n4. The water molecules are distributed according to their equilibrium constant.\n\nKeep in mind that chemical reactions are complex processes, and the actual mechanisms can be influenced by various factors, such as catalysts, solvent effects, and reaction conditions."
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"How do two chemicals react?\"}],\n",
        "    temperature = 0.8,\n",
        ")\n",
        "\n",
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e7bac7-52f6-4779-a2a3-d45d29975f5d",
      "metadata": {
        "id": "c7e7bac7-52f6-4779-a2a3-d45d29975f5d"
      },
      "source": [
        "**Exercise:** Ask the same question but modify the prompt to return the answer to the same question in a simpler form (still using the llama-3.1-8b-instant model). Experiment with different prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "92250b60-9d68-4906-80b8-db78fc9c2ae6",
      "metadata": {
        "id": "92250b60-9d68-4906-80b8-db78fc9c2ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "18f929a6-3237-46c6-9b74-302e5a418e94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Let's consider a simple example of how two chemicals react: baking soda (sodium bicarbonate) and vinegar (acetic acid).\n\n**Chemical Reaction:**\n\nWhen you mix baking soda and vinegar, a chemical reaction occurs. Here's what happens:\n\n1. **Baking Soda (Sodium Bicarbonate)**: This is a white, powdery substance that is commonly used in baking.\n2. **Vinegar (Acetic Acid)**: This is a clear, liquid substance that is commonly used in cooking and as a cleaning agent.\n\n**The Reaction:**\n\nWhen you mix baking soda and vinegar, they react to form carbon dioxide gas (a gas that makes things bubbly). This reaction is called a chemical reaction.\n\nHere's a simplified equation:\n\nNaHCO3 (baking soda) + CH3COOH (vinegar) → CO2 (carbon dioxide) + H2O (water)\n\n**What happens:**\n\nWhen you mix baking soda and vinegar, the following happens:\n\n* The baking soda (sodium bicarbonate) reacts with the vinegar (acetic acid) to form carbon dioxide gas.\n* The carbon dioxide gas is released into the air, creating bubbles.\n* The mixture also forms water, which is a byproduct of the reaction.\n\n**Result:**\n\nThe result of the reaction is a fizzing or bubbling mixture that is often used in science experiments and baking recipes.\n\n**Why it's important:**\n\nThis reaction is important because it shows how two chemicals can interact with each other to form new substances. This is a fundamental concept in chemistry, and it's used in many different fields, including cooking, medicine, and engineering.\n\nI hope this helps you understand how two chemicals react! Let me know if you have any other questions."
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# ANSWER\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Explain how two chemicals react, in simple terms for a beginner.\"\n",
        "    }],\n",
        "    temperature=0.7,\n",
        ")\n",
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Explain how two chemicals react, in simple terms for a beginner.\"\n",
        "    }],\n",
        "    temperature=0.3,\n",
        ")\n",
        "Markdown(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "x7R-S_clfp42",
        "outputId": "1de86174-6f81-433b-ed2e-a3797695c690"
      },
      "id": "x7R-S_clfp42",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Let's consider a simple example of a chemical reaction between two chemicals: baking soda (sodium bicarbonate) and vinegar (acetic acid).\n\n**Chemical Reaction:**\n\nBaking soda (NaHCO3) + Vinegar (CH3COOH) → Carbon dioxide (CO2) + Water (H2O) + Salt (NaAc)\n\n**What happens:**\n\n1. When you mix baking soda and vinegar together, they start to react with each other.\n2. The acid in the vinegar (acetic acid) breaks down the baking soda (sodium bicarbonate).\n3. This breakdown releases carbon dioxide gas, which is what makes the mixture fizz and bubble.\n4. The reaction also produces water and a type of salt called sodium acetate.\n\n**Visual representation:**\n\nImagine a seesaw with baking soda on one side and vinegar on the other. When you mix them together, the seesaw tips, and the baking soda and vinegar react with each other. The carbon dioxide gas released in the reaction is like a \"bubble\" that makes the mixture fizz and bubble.\n\n**Key points:**\n\n- Chemical reactions involve the interaction of two or more substances.\n- The reactants (baking soda and vinegar) combine to form new substances (carbon dioxide, water, and salt).\n- Chemical reactions can release energy in the form of heat, light, or in this case, gas bubbles.\n\nThis is a simple example of a chemical reaction, but there are many more complex reactions that occur in the world around us."
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Explain how two chemicals react, using simple sentences.\"\n",
        "    }],\n",
        "    temperature=0.3,\n",
        ")\n",
        "Markdown(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "NHpl9NTHf1Eb",
        "outputId": "2aa68629-13bf-40ff-db76-99bb400e9f9e"
      },
      "id": "NHpl9NTHf1Eb",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Let's consider the reaction between hydrogen peroxide (H2O2) and yeast. \n\nYeast is a living organism that contains an enzyme called catalase. \nCatalase breaks down hydrogen peroxide into water (H2O) and oxygen gas (O2).\nThe reaction is as follows: H2O2 → H2O + O2.\n\nHere's a step-by-step explanation:\n\n1. The yeast cell membrane allows hydrogen peroxide to enter the cell.\n2. The catalase enzyme in the yeast cell breaks down the hydrogen peroxide molecule.\n3. The hydrogen peroxide molecule is split into two water molecules and one oxygen molecule.\n4. The oxygen molecule is released as a gas, creating bubbles.\n5. The reaction continues as long as there is hydrogen peroxide present and the yeast cells are alive.\n\nThis reaction is an example of a catalytic reaction, where the enzyme (catalase) speeds up the reaction without being consumed by it."
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04676a11-57a7-4f9c-87e2-128559f0ffce",
      "metadata": {
        "id": "04676a11-57a7-4f9c-87e2-128559f0ffce"
      },
      "source": [
        "### One-shot prompting ###\n",
        "\n",
        "Next, note the dramatic change when we give the following template setting a new role and providing an English question followed by a French translation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "fcb1c8fa-d3cb-400d-ae0f-3bc8f2d1d473",
      "metadata": {
        "id": "fcb1c8fa-d3cb-400d-ae0f-3bc8f2d1d473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39d0eb6-2820-4506-a444-288a3ef11e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment deux composés chimiques réagissent-ils?\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"system\",\n",
        "             \"content\": \"You translate English to French.\"},\n",
        "              {\"role\": \"user\",\n",
        "               \"content\": \"What time is it?\"},\n",
        "               {\"role\": \"assistant\",\n",
        "               \"content\": \"Quelle heure est-il?\"},\n",
        "              {\"role\": \"user\",\n",
        "               \"content\": \"How do two chemicals react?\"}],\n",
        "    temperature = 0.8,\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc1394e5-34b9-46b8-aea6-87a7862b7269",
      "metadata": {
        "id": "fc1394e5-34b9-46b8-aea6-87a7862b7269"
      },
      "source": [
        "### Few-shot prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e3b3d0-c365-4138-9be0-9d324bc34050",
      "metadata": {
        "id": "d5e3b3d0-c365-4138-9be0-9d324bc34050"
      },
      "source": [
        "Recall that since the text generation process outputs one token at a time, their outputs often need adjusting. This is where examples can help."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "68c6131b-3b30-45b0-8dab-0dc547033b6b",
      "metadata": {
        "id": "68c6131b-3b30-45b0-8dab-0dc547033b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f449422-7997-46ba-f6a9-3758a5036b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regrettably, I will be unable to attend the meeting. I apologize for any inconvenience this may cause.\n"
          ]
        }
      ],
      "source": [
        "prompt1 = \"I'm gonna head out now, see you later.\"\n",
        "response1 = \"I will be leaving now. See you later.\"\n",
        "\n",
        "prompt2 =  \"That movie was super cool!\"\n",
        "response2 = \"The movie was very impressive.\"\n",
        "\n",
        "prompt3 = \"Can't make it to the meeting, sorry.\"\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional editor. Rewrite casual sentences into a formal tone.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt1},\n",
        "        {\"role\": \"assistant\", \"content\": response1},\n",
        "        {\"role\": \"user\", \"content\": prompt2},\n",
        "        {\"role\": \"assistant\", \"content\": response2},\n",
        "        {\"role\": \"user\", \"content\": prompt3},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "040e9e18-cc27-453b-8844-3f683fb607f8",
      "metadata": {
        "id": "040e9e18-cc27-453b-8844-3f683fb607f8"
      },
      "source": [
        "The output can also be moulded to provide SQL output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ed854534-30db-4745-b910-27d12a3ed47e",
      "metadata": {
        "id": "ed854534-30db-4745-b910-27d12a3ed47e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84e61fd-e26f-4575-9fcf-2defc7d49ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT * FROM products WHERE stock_quantity = 0;\n"
          ]
        }
      ],
      "source": [
        "prompt1 = \"Show me all users who signed up in the last 30 days.\"\n",
        "response1 = \"SELECT * FROM users WHERE signup_date >= CURRENT_DATE - INTERVAL '30 days';\"\n",
        "\n",
        "prompt2 = \"What is the average order value?\"\n",
        "response2 =  \"SELECT AVG(order_total) FROM orders;\"\n",
        "\n",
        "prompt3 = \"List products that are out of stock.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant that translates natural language to SQL.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt1},\n",
        "        {\"role\": \"assistant\", \"content\": response1},\n",
        "        {\"role\": \"user\", \"content\": prompt2},\n",
        "        {\"role\": \"assistant\", \"content\": response2},\n",
        "        {\"role\": \"user\", \"content\": prompt3},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a1dda2-2913-4a59-bfc3-3f0a59f0dcc7",
      "metadata": {
        "id": "45a1dda2-2913-4a59-bfc3-3f0a59f0dcc7"
      },
      "source": [
        "**Exercise**: Create a few examples to train the \"llama3-70b-8192\" LLM to take in user content in the form below and provide output as a pandas dataframe. Use the `exec` function to execute its output to display the answer of sample input as a data frame.\n",
        "\n",
        "Example:\n",
        "\n",
        "given the user content\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "| col1 | col2 | col3\n",
        "\n",
        "| 32 | 27 | 25\n",
        "\n",
        "| 64 | 23 | 14\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "train the model to output\n",
        "\n",
        "df = pd.DataFrame({'col1': [32, 64], 'col2': [27, 23], 'col3': [25, 14]})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2b8ac08a-5759-41cd-a560-e77694573723",
      "metadata": {
        "id": "2b8ac08a-5759-41cd-a560-e77694573723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "2aef7842-fd61-4366-a5dc-e204c58d1c40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   colA  colB  colC\n",
              "0    23    12    54\n",
              "1     8    76    32\n",
              "2     7     5     3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d64fb457-fa33-4003-a686-51a081fd2489\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>colA</th>\n",
              "      <th>colB</th>\n",
              "      <th>colC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>76</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d64fb457-fa33-4003-a686-51a081fd2489')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d64fb457-fa33-4003-a686-51a081fd2489 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d64fb457-fa33-4003-a686-51a081fd2489');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ea0e7bdf-54e2-4920-88e4-4c12df4dd4b7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea0e7bdf-54e2-4920-88e4-4c12df4dd4b7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ea0e7bdf-54e2-4920-88e4-4c12df4dd4b7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5b704dab-6494-450e-8b4d-30d8892ec8e1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5b704dab-6494-450e-8b4d-30d8892ec8e1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"colA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 7,\n        \"max\": 23,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          23,\n          8,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"colB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 5,\n        \"max\": 76,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          12,\n          76,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"colC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 3,\n        \"max\": 54,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          54,\n          32,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#ANSWER\n",
        "\n",
        "#ANSWER\n",
        "\n",
        "user1 = \"\"\"col1 | col2 | col3\n",
        "32 | 27 | 25\n",
        "64 | 23 | 14\n",
        "\"\"\"\n",
        "\n",
        "output1 = \"\"\"\n",
        "df = pd.DataFrame({'col1': [32, 64], 'col2': [27, 23], 'col3': [25, 14]})\n",
        "\"\"\"\n",
        "\n",
        "user2 = \"\"\"col1 | col2\n",
        "23 | 12\n",
        "8 | 76\n",
        "7 | 5\n",
        "\"\"\"\n",
        "output2 = \"\"\"\n",
        "df = pd.DataFrame({'col1': [23, 8, 7], 'col2': [12, 76, 5]})\n",
        "\"\"\"\n",
        "user3 = \"\"\"colA | colB | colC\n",
        "23 | 12 | 54\n",
        "8 | 76 | 32\n",
        "7 | 5 | 3\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a data scientist who will receive data input as a string and provide output as a pandas dataframe called df. Use the examples to guide you\"},\n",
        "        {\"role\": \"user\", \"content\": user1},\n",
        "        {\"role\": \"assistant\", \"content\": output1},\n",
        "        {\"role\": \"user\", \"content\": user2},\n",
        "        {\"role\": \"user\", \"content\": output2},\n",
        "        {\"role\": \"user\", \"content\": user3}\n",
        "    ]\n",
        ")\n",
        "\n",
        "exec(response.choices[0].message.content.strip()) # string executed as Python code\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29f62a88-c7b4-4431-acda-97e9a98981f4",
      "metadata": {
        "id": "29f62a88-c7b4-4431-acda-97e9a98981f4"
      },
      "source": [
        "Also show what happens when the question is asked in the absence of a system role and without few-shot prompting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "712221ea-14c0-4faa-a126-ca4f2f0538a6",
      "metadata": {
        "id": "712221ea-14c0-4faa-a126-ca4f2f0538a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e4685e7a-f5de-4128-9aa0-f97368ff364b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It looks like you're showing a table with three columns: `colA`, `colB`, and `colC`, and three rows of data.\\n\\nIs there something you'd like to do with this data, such as:\\n\\n* Perform a calculation or aggregation (e.g. sum, average, min, max)?\\n* Filter or sort the data based on certain conditions?\\n* Merge this data with another table or dataset?\\n* Visualize the data in a chart or graph?\\n\\nLet me know, and I'll do my best to assist you!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# ANSWER\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user3}\n",
        "    ]\n",
        ")\n",
        "response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28660884-dfd4-4b96-a65d-d21ddbf99423",
      "metadata": {
        "id": "28660884-dfd4-4b96-a65d-d21ddbf99423"
      },
      "source": [
        "### Chain-of-thought prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "724f85ef-afc0-4e31-9ad8-ae780c535837",
      "metadata": {
        "id": "724f85ef-afc0-4e31-9ad8-ae780c535837"
      },
      "source": [
        "The results of question-answering can also be improved by prompting the LLM to provide intermediate steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bee04ad6-968b-406a-8119-981b01ef5f92",
      "metadata": {
        "id": "bee04ad6-968b-406a-8119-981b01ef5f92"
      },
      "source": [
        "**Exercise**: Using the following prompts, compare the answers of the \"llama3-8b-8192\" model (set seed=21). (If this model is no longer available choose a model with relatively few parameters.)\n",
        "\n",
        "zero_shot_prompt = \"How many s's are in the word 'success'?\"\n",
        "\n",
        "chain_of_thought_prompt = \"How many s's are in the word 'success'? Explain your answer step by step by going through each letter in turn.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "bc8868f2-7c4f-4b99-bbd2-cc731cca74bb",
      "metadata": {
        "id": "bc8868f2-7c4f-4b99-bbd2-cc731cca74bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2847265-4cdc-4788-e612-ab834cad6016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------zero-shot-prompt------\n",
            "There are 2 s's in the word 'success'.\n",
            "------chain-of-thought------\n",
            "To count the number of 's's in the word \"success\", we'll go through each letter one by one:\n",
            "\n",
            "1. The word is \"succe**s**s\".\n",
            "2. The first letter is 's' (one 's').\n",
            "3. The second letter is 'u'.\n",
            "4. The third letter is 'c'.\n",
            "5. The fourth letter is 'c'.\n",
            "6. The fifth letter is 'e'.\n",
            "7. The sixth letter is 's' (second 's').\n",
            "8. The seventh letter is 's' (third 's').\n",
            "\n",
            "After counting the letters, we have three 's's in the word \"success\".\n"
          ]
        }
      ],
      "source": [
        "# ANSWER\n",
        "# ANSWER\n",
        "zero_shot_prompt = \"How many s's are in the word 'success'?\"\n",
        "chain_of_thought_prompt = \"How many s's are in the word 'success'? Explain your answer step by step by going through each letter in turn.\"\n",
        "\n",
        "response1 = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    seed = 21\n",
        ")\n",
        "\n",
        "response2 = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": chain_of_thought_prompt}],\n",
        "    seed = 21\n",
        ")\n",
        "\n",
        "print('------zero-shot-prompt------')\n",
        "print(response1.choices[0].message.content)\n",
        "\n",
        "print('------chain-of-thought------')\n",
        "print(response2.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09499b6e-a4aa-439c-a785-3f0e06a3ba4f",
      "metadata": {
        "id": "09499b6e-a4aa-439c-a785-3f0e06a3ba4f"
      },
      "source": [
        "## Comparison of LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0e82d9-cefc-4af3-9d95-5e22db6cd56f",
      "metadata": {
        "id": "dd0e82d9-cefc-4af3-9d95-5e22db6cd56f"
      },
      "source": [
        "**Exercise**: Compare the performance of 2 LLMs by outputting the answers of the following questions into a dataframe.\n",
        "\n",
        "    \"Tell me a joke about data science.\",\n",
        "    \"How can one calculate 22 * 13 mentally?\",\n",
        "    \"Write a creative story about a baby learning to crawl.\",\n",
        "\n",
        "Column headings:\n",
        "\n",
        "Model Name | Question | Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b5e0c587-9650-4082-baf4-d9cdd94bc238",
      "metadata": {
        "id": "b5e0c587-9650-4082-baf4-d9cdd94bc238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00bb9e7e-5303-48ac-f23e-ba7f0ce6ec23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Model Name  \\\n",
              "0          gemma2-9b-it   \n",
              "1          gemma2-9b-it   \n",
              "2          gemma2-9b-it   \n",
              "3  llama-3.1-8b-instant   \n",
              "4  llama-3.1-8b-instant   \n",
              "5  llama-3.1-8b-instant   \n",
              "\n",
              "                                                 Question  \\\n",
              "0                      Tell me a joke about data science.   \n",
              "1                 How can one calculate 22 * 13 mentally?   \n",
              "2  Write a creative story about a baby learning to crawl.   \n",
              "3                      Tell me a joke about data science.   \n",
              "4                 How can one calculate 22 * 13 mentally?   \n",
              "5  Write a creative story about a baby learning to crawl.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Answer  \n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Why did the data scientist break up with the statistician? \\n\\nBecause they had too many \"significant differences\"!  😂  \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Here's a way to calculate 22 * 13 mentally using a bit of cleverness:\\n\\n**1. Break down the numbers:**\\n\\n*  Think of 22 as (20 + 2) \\n\\n**2.  Distribute:**\\n\\n*  (20 + 2) * 13 \\n*  = 20 * 13 + 2 * 13\\n\\n**3. Calculate the easier parts:**\\n\\n*  20 * 13 = 260\\n*  2 * 13 = 26\\n\\n**4. Add the results:**\\n\\n*  260 + 26 = 286\\n\\n\\n\\nLet me know if you'd like to try another mental math problem!  \n",
              "2  Bartholomew \"Bartleby\" Buttercup was a momentous baby. Not just in the way that all babies are momentous, with their first coos and gummy grins, but in his sheer determination to learn to crawl. His older sister, Poppy, zoomed around the room like a furry, four-legged rocket, leaving trails of building blocks and dropped crayons in her wake. Bartleby, however, remained rooted, surrounded by a galaxy of toys he desperately wanted to reach. \\n\\nHis movements were epic, if a little slow. He’d fling his fists at the air, his chubby legs kicking out with the force of a startled frog.  He'd squirm and wiggle, sending his bright red diaper into a frenzied dance. But those chubby, determined legs refused to cooperate in the synchronized effort required for crawling.\\n\\nOne sunny afternoon, Poppy, in her usual whirlwind fashion, toppled over Bartleby’s beloved stuffed caterpillar, Mr. Flutterkins. Mr. Flutterkins landed on his back, his tiny felt antennae dangling pathetically. A pained gurgle escaped Bartleby’s lips. Poppy, ever the adventurer, scrambled over the fallen toy, oblivious to the distress she'd caused. \\n\\nBartleby watched her with a mixture of awe and frustration. His eyes, wide and blue like a summer sky, drilled into the back of Poppy's head. Then, a strange thing happened. His legs, in a sudden burst of unexpected action, propelled him forward. \\n\\nHe bumped, he slid, he wobbled, but he was moving. He was crawling!  \\n\\nPoppy, mid-adventure, paused, her head swiveling to look at Bartleby. Her eyes widened in surprise. Bartleby, fueled by a primal urge to rescue Mr. Flutterkins, kept going. He bumped into a stack of books, sending them cascading to the floor. He wriggled under the coffee table, narrowly avoiding a collision with a stray sock.\\n\\nFinally, he reached Mr. Flutterkins, his grubby hands scooping up the fallen toy. He held Mr. Flutterkins aloft, his face beaming with triumph. \\n\\nPoppy, forgetting her own adventures, clambered down and joined him, giggling. They played together, Bartleby pulling himself forward in a jerky, determined crawl, while Poppy chased him, her laughter echoing through the room.\\n\\n\\nBartleby, the once stationary baby, had conquered the holy grail of crawling. He’d even done it in his own unique way, fuelled by love for a stuffed caterpillar and a fierce resolve to move.  And somewhere in that joyous chaos, under the watchful gaze of a happy mother, another monumental moment blossomed - the moment siblings truly understood each other.  \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Why did the data scientist quit his job?\\n\\nBecause he didn't get any data out of his decision.  \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 To calculate 22 * 13 mentally, you can use a technique called the \"nines trick\" in combination with estimation. However, a simpler method involves breaking down the multiplication into known numbers and using some mental math techniques.\\n\\nMethod 1: Break down the numbers\\n\\nFirst, break down 13 into a sum of 10 and 3:\\n22 * (10 + 3) = 22 * 10 + 22 * 3\\n\\nNext, calculate the individual parts:\\n- 22 * 10 = 220 (multiply 22 by 20 and add the remaining 2)\\n  22 * 20 = 440\\n  Add the remaining 2: 440 + 2 = 442\\n- Since the actual multiplication was 22 * 3, calculate that directly: Multiply 22 by 3 to get 66.\\n\\nNow, add the results: 442 + 66 = 508.\\n\\nMethod 2: Use the lattice or the nines trick isn't directly necessary here. Break down 13 into a sum of 10 and 3, and remember that you've already multiplied this by 20 and added 2 in the first calculation (220). For 3 * 22, remember 22 is (20 + 2) so we get (3 * 20) + (3 * 2) = 3 * 20 + 6.\\n\\nSince 3 * 20 is actually 60, adding the 6 (that came from 3 * 2), gives you 66. Adding the results of both calculations: 442 and 66, which is still 508.\\n\\nMethod 3 (Lattice):\\n- Use a lattice or diagram.\\n- Multiply the tens of the numbers (2 * 1 = 2), then add the ones of the numbers (2 * 3 = 6, and place the tens 6 in the tens place, so you get 20, and then add 6 in the ones place).\\n- Add the results: \\n  20 + 30 = 50\\n  00 + 00 = 0\\n  Add the last digit (the '0 + 6' in this case). \\n  The final answer is indeed 282 so the last digit is indeed 6 and 50 + 0 + 6 = 286.  \n",
              "5                                                         In a cozy little nest of soft blankets and pillows, a tiny bundle of joy lay sprawled out, staring up at the vibrant hues of a colorful mobile dangling above. Baby Emily's big, bright eyes sparkled with curiosity as she gazed around her nursery, eager to tackle the next chapter of her exciting journey.\\n\\nShe had been steadily improving her motor skills for weeks – rolling from side to side, propping herself up on her elbows, and, most recently, attempting to lift her head off the mattress. The day had finally come for Emily to take the ultimate test: crawling.\\n\\nAs soon as her mother laid her down on the playmat, Emily sensed the challenge within her grasp. She watched intently as her fingers curled and uncurled, itching to grasp something – anything – that would set her on the path to becoming a pro crawler.\\n\\nWith a squeal of excitement, Emily launched herself forward, her arms flailing wildly like a little bird taking flight. She grasped at the air, missing the desired object every time. Her face scrunched up in determination, she took a deep breath and tried again.\\n\\nThis time, her hands landed on the soft cushion of the playmat, and, with a squeal of delight, Emily pulled herself forward, her legs kicking furiously as she inched her way toward a nearby toy. She paused, panting with excitement, and examined her surroundings. A nearby stuffed rabbit had caught her eye, and with a mischievous grin, she crept toward it.\\n\\nThe baby took a few more tentative crawling steps, her muscles straining with the effort. Each time she pulled herself forward, she let out a triumphant coo. Her mother, watching from the sidelines, smiled with pride, snapping photos and making mental notes to commemorate this momentous occasion.\\n\\nAs the day wore on, Emily's confidence grew, and she began to crawl more efficiently, her hands pushing her toward the various toys and trinkets strewn around the playmat. She discovered a fascination with a nearby mobile, batting at the colorful shapes with her sticky little fingers. And, just when she thought she'd made it to the top of the world, Emily launched herself onto her hands and knees once more, crawling triumphantly toward the next adventure.\\n\\nIn that moment, Emily realized that she was capable of anything – that the world was hers for the taking. And with a beaming smile on her face and a twinkle in her eye, she continued on her journey, crawling boldly into the next chapter of her life.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d8e0fe0-5a3f-4f4d-a945-c6114042efd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gemma2-9b-it</td>\n",
              "      <td>Tell me a joke about data science.</td>\n",
              "      <td>Why did the data scientist break up with the statistician? \\n\\nBecause they had too many \"significant differences\"!  😂</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gemma2-9b-it</td>\n",
              "      <td>How can one calculate 22 * 13 mentally?</td>\n",
              "      <td>Here's a way to calculate 22 * 13 mentally using a bit of cleverness:\\n\\n**1. Break down the numbers:**\\n\\n*  Think of 22 as (20 + 2) \\n\\n**2.  Distribute:**\\n\\n*  (20 + 2) * 13 \\n*  = 20 * 13 + 2 * 13\\n\\n**3. Calculate the easier parts:**\\n\\n*  20 * 13 = 260\\n*  2 * 13 = 26\\n\\n**4. Add the results:**\\n\\n*  260 + 26 = 286\\n\\n\\n\\nLet me know if you'd like to try another mental math problem!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gemma2-9b-it</td>\n",
              "      <td>Write a creative story about a baby learning to crawl.</td>\n",
              "      <td>Bartholomew \"Bartleby\" Buttercup was a momentous baby. Not just in the way that all babies are momentous, with their first coos and gummy grins, but in his sheer determination to learn to crawl. His older sister, Poppy, zoomed around the room like a furry, four-legged rocket, leaving trails of building blocks and dropped crayons in her wake. Bartleby, however, remained rooted, surrounded by a galaxy of toys he desperately wanted to reach. \\n\\nHis movements were epic, if a little slow. He’d fling his fists at the air, his chubby legs kicking out with the force of a startled frog.  He'd squirm and wiggle, sending his bright red diaper into a frenzied dance. But those chubby, determined legs refused to cooperate in the synchronized effort required for crawling.\\n\\nOne sunny afternoon, Poppy, in her usual whirlwind fashion, toppled over Bartleby’s beloved stuffed caterpillar, Mr. Flutterkins. Mr. Flutterkins landed on his back, his tiny felt antennae dangling pathetically. A pained gurgle escaped Bartleby’s lips. Poppy, ever the adventurer, scrambled over the fallen toy, oblivious to the distress she'd caused. \\n\\nBartleby watched her with a mixture of awe and frustration. His eyes, wide and blue like a summer sky, drilled into the back of Poppy's head. Then, a strange thing happened. His legs, in a sudden burst of unexpected action, propelled him forward. \\n\\nHe bumped, he slid, he wobbled, but he was moving. He was crawling!  \\n\\nPoppy, mid-adventure, paused, her head swiveling to look at Bartleby. Her eyes widened in surprise. Bartleby, fueled by a primal urge to rescue Mr. Flutterkins, kept going. He bumped into a stack of books, sending them cascading to the floor. He wriggled under the coffee table, narrowly avoiding a collision with a stray sock.\\n\\nFinally, he reached Mr. Flutterkins, his grubby hands scooping up the fallen toy. He held Mr. Flutterkins aloft, his face beaming with triumph. \\n\\nPoppy, forgetting her own adventures, clambered down and joined him, giggling. They played together, Bartleby pulling himself forward in a jerky, determined crawl, while Poppy chased him, her laughter echoing through the room.\\n\\n\\nBartleby, the once stationary baby, had conquered the holy grail of crawling. He’d even done it in his own unique way, fuelled by love for a stuffed caterpillar and a fierce resolve to move.  And somewhere in that joyous chaos, under the watchful gaze of a happy mother, another monumental moment blossomed - the moment siblings truly understood each other.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>llama-3.1-8b-instant</td>\n",
              "      <td>Tell me a joke about data science.</td>\n",
              "      <td>Why did the data scientist quit his job?\\n\\nBecause he didn't get any data out of his decision.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>llama-3.1-8b-instant</td>\n",
              "      <td>How can one calculate 22 * 13 mentally?</td>\n",
              "      <td>To calculate 22 * 13 mentally, you can use a technique called the \"nines trick\" in combination with estimation. However, a simpler method involves breaking down the multiplication into known numbers and using some mental math techniques.\\n\\nMethod 1: Break down the numbers\\n\\nFirst, break down 13 into a sum of 10 and 3:\\n22 * (10 + 3) = 22 * 10 + 22 * 3\\n\\nNext, calculate the individual parts:\\n- 22 * 10 = 220 (multiply 22 by 20 and add the remaining 2)\\n  22 * 20 = 440\\n  Add the remaining 2: 440 + 2 = 442\\n- Since the actual multiplication was 22 * 3, calculate that directly: Multiply 22 by 3 to get 66.\\n\\nNow, add the results: 442 + 66 = 508.\\n\\nMethod 2: Use the lattice or the nines trick isn't directly necessary here. Break down 13 into a sum of 10 and 3, and remember that you've already multiplied this by 20 and added 2 in the first calculation (220). For 3 * 22, remember 22 is (20 + 2) so we get (3 * 20) + (3 * 2) = 3 * 20 + 6.\\n\\nSince 3 * 20 is actually 60, adding the 6 (that came from 3 * 2), gives you 66. Adding the results of both calculations: 442 and 66, which is still 508.\\n\\nMethod 3 (Lattice):\\n- Use a lattice or diagram.\\n- Multiply the tens of the numbers (2 * 1 = 2), then add the ones of the numbers (2 * 3 = 6, and place the tens 6 in the tens place, so you get 20, and then add 6 in the ones place).\\n- Add the results: \\n  20 + 30 = 50\\n  00 + 00 = 0\\n  Add the last digit (the '0 + 6' in this case). \\n  The final answer is indeed 282 so the last digit is indeed 6 and 50 + 0 + 6 = 286.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>llama-3.1-8b-instant</td>\n",
              "      <td>Write a creative story about a baby learning to crawl.</td>\n",
              "      <td>In a cozy little nest of soft blankets and pillows, a tiny bundle of joy lay sprawled out, staring up at the vibrant hues of a colorful mobile dangling above. Baby Emily's big, bright eyes sparkled with curiosity as she gazed around her nursery, eager to tackle the next chapter of her exciting journey.\\n\\nShe had been steadily improving her motor skills for weeks – rolling from side to side, propping herself up on her elbows, and, most recently, attempting to lift her head off the mattress. The day had finally come for Emily to take the ultimate test: crawling.\\n\\nAs soon as her mother laid her down on the playmat, Emily sensed the challenge within her grasp. She watched intently as her fingers curled and uncurled, itching to grasp something – anything – that would set her on the path to becoming a pro crawler.\\n\\nWith a squeal of excitement, Emily launched herself forward, her arms flailing wildly like a little bird taking flight. She grasped at the air, missing the desired object every time. Her face scrunched up in determination, she took a deep breath and tried again.\\n\\nThis time, her hands landed on the soft cushion of the playmat, and, with a squeal of delight, Emily pulled herself forward, her legs kicking furiously as she inched her way toward a nearby toy. She paused, panting with excitement, and examined her surroundings. A nearby stuffed rabbit had caught her eye, and with a mischievous grin, she crept toward it.\\n\\nThe baby took a few more tentative crawling steps, her muscles straining with the effort. Each time she pulled herself forward, she let out a triumphant coo. Her mother, watching from the sidelines, smiled with pride, snapping photos and making mental notes to commemorate this momentous occasion.\\n\\nAs the day wore on, Emily's confidence grew, and she began to crawl more efficiently, her hands pushing her toward the various toys and trinkets strewn around the playmat. She discovered a fascination with a nearby mobile, batting at the colorful shapes with her sticky little fingers. And, just when she thought she'd made it to the top of the world, Emily launched herself onto her hands and knees once more, crawling triumphantly toward the next adventure.\\n\\nIn that moment, Emily realized that she was capable of anything – that the world was hers for the taking. And with a beaming smile on her face and a twinkle in her eye, she continued on her journey, crawling boldly into the next chapter of her life.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d8e0fe0-5a3f-4f4d-a945-c6114042efd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d8e0fe0-5a3f-4f4d-a945-c6114042efd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d8e0fe0-5a3f-4f4d-a945-c6114042efd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6ec39d77-4cdb-47e0-affc-fdf0ea2e3d0b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ec39d77-4cdb-47e0-affc-fdf0ea2e3d0b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6ec39d77-4cdb-47e0-affc-fdf0ea2e3d0b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_346e5e08-9560-40f7-bad1-dcb6b7b45595\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_346e5e08-9560-40f7-bad1-dcb6b7b45595 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"llama-3.1-8b-instant\",\n          \"gemma2-9b-it\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Tell me a joke about data science.\",\n          \"How can one calculate 22 * 13 mentally?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Why did the data scientist break up with the statistician? \\n\\nBecause they had too many \\\"significant differences\\\"!  \\ud83d\\ude02\",\n          \"Here's a way to calculate 22 * 13 mentally using a bit of cleverness:\\n\\n**1. Break down the numbers:**\\n\\n*  Think of 22 as (20 + 2) \\n\\n**2.  Distribute:**\\n\\n*  (20 + 2) * 13 \\n*  = 20 * 13 + 2 * 13\\n\\n**3. Calculate the easier parts:**\\n\\n*  20 * 13 = 260\\n*  2 * 13 = 26\\n\\n**4. Add the results:**\\n\\n*  260 + 26 = 286\\n\\n\\n\\nLet me know if you'd like to try another mental math problem!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None) # allows wide dataframes to be viewed\n",
        "models = [\"gemma2-9b-it\", \"llama-3.1-8b-instant\"] #can edit this\n",
        "\n",
        "# ANSWER\n",
        "prompts = [\n",
        "    \"Tell me a joke about data science.\",\n",
        "    \"How can one calculate 22 * 13 mentally?\",\n",
        "    \"Write a creative story about a baby learning to crawl.\",\n",
        "]\n",
        "\n",
        "results = {'Model Name': [], 'Question': [], 'Answer': []}\n",
        "\n",
        "for model in models:\n",
        "    for prompt in prompts:\n",
        "        results['Model Name'].append(model)\n",
        "        results['Question'].append(prompt)\n",
        "        try:\n",
        "            output = client.chat.completions.create(model = model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
        "            results['Answer'].append(output.choices[0].message.content.strip())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with {model}: {e}\")\n",
        "            results['Answer'].append((prompt, \"ERROR\"))\n",
        "\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f3e2651-0bee-40bd-b5cc-3c2891b1adb5",
      "metadata": {
        "id": "8f3e2651-0bee-40bd-b5cc-3c2891b1adb5"
      },
      "source": [
        "### Bonus\n",
        "\n",
        "See if you can prompt an LLM to perform sentiment analysis (output 'Positive' or 'Negative' only) on a given piece of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d7169fd6-f1d1-4a5d-8fd9-21167a54416a",
      "metadata": {
        "id": "d7169fd6-f1d1-4a5d-8fd9-21167a54416a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3583cb62-ba29-46f6-ac82-1a75ce8b1b21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# ANSWER\n",
        "input1 = \"I was inspired by the actor's performance.\"\n",
        "output1 = \"Positive\"\n",
        "\n",
        "input2 = \"The traffic is so heavy today.\"\n",
        "output2 = \"Negative\"\n",
        "\n",
        "input3 = \"He opened a business today.\"\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are amazing at sentiment analysis. Give the sentiment of the next sentence as the examples show.\"},\n",
        "        {\"role\": \"user\", \"content\": input1},\n",
        "        {\"role\": \"assistant\", \"content\": output1},\n",
        "        {\"role\": \"user\", \"content\": input2},\n",
        "        {\"role\": \"assistant\", \"content\": output2},\n",
        "        {\"role\": \"user\", \"content\": input3},\n",
        "    ]\n",
        ")\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0387259e-0bf8-400e-97d9-d3f5688b2e4d",
      "metadata": {
        "id": "0387259e-0bf8-400e-97d9-d3f5688b2e4d"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f279421d-cbca-4003-941e-c2d2bc2833a8",
      "metadata": {
        "id": "f279421d-cbca-4003-941e-c2d2bc2833a8"
      },
      "source": [
        "We worked with a few Large Language Models (LLMs) using Groq and experimented with prompting for summarisation, text completion and question-answering tasks.\n",
        "\n",
        "We also explored controlling the randomness (creativity) of output through the temperature setting and tried different types of prompting to achieve desired forms of output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f06d5e-7073-485b-b046-afe839ab844c",
      "metadata": {
        "id": "94f06d5e-7073-485b-b046-afe839ab844c"
      },
      "source": [
        "## References\n",
        "1. [Groq's prompting guide](https://console.groq.com/docs/prompting)\n",
        "2. [Groq's playground](https://console.groq.com/playground)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d61aab4a-1330-4762-9318-5635c3a97aa7",
      "metadata": {
        "id": "d61aab4a-1330-4762-9318-5635c3a97aa7"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> > > > > > > > > © 2025 Institute of Data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}